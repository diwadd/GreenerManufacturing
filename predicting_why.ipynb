{
 "metadata": {
  "name": "",
  "signature": "sha256:958cc5c026195bf2cefaaf218f0750d054cc2190b65bca4793729bcc37d7efb3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "from keras.layers import Input, Dense, Dropout\n",
      "from keras.layers.advanced_activations import LeakyReLU\n",
      "from keras.models import Model, Sequential\n",
      "import keras.backend as K\n",
      "\n",
      "from keras.models import load_model\n",
      "\n",
      "import xgboost as xgb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/tadek/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
        "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Load the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_ID_y = np.genfromtxt(\"features_ID_y.csv\", delimiter=',')\n",
      "np.random.shuffle(features_ID_y)\n",
      "n_rows, n_cols = features_ID_y.shape\n",
      "print(features_ID_y[0:10,0:5])\n",
      "print(\"Number of rows: \" + str(n_rows))\n",
      "print(\"Number of cols: \" + str(n_cols))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  7.15800000e+03   9.45899963e+01   5.20000000e+01   3.00000000e+00\n",
        "    3.70000000e+01]\n",
        " [  7.33500000e+03   1.28800003e+02   1.50000000e+01   1.30000000e+01\n",
        "    4.30000000e+01]\n",
        " [  6.92400000e+03   8.91500015e+01   1.60000000e+01   1.40000000e+01\n",
        "    1.90000000e+01]\n",
        " [  6.98800000e+03   8.99800034e+01   4.00000000e+01   0.00000000e+00\n",
        "    1.10000000e+01]\n",
        " [  5.09000000e+03   7.47600021e+01   2.40000000e+01   2.00000000e+01\n",
        "    2.90000000e+01]\n",
        " [  3.51000000e+02   1.06139999e+02   1.00000000e+01   1.30000000e+01\n",
        "    4.20000000e+01]\n",
        " [  6.85000000e+03   8.71200027e+01   2.50000000e+01   3.00000000e+00\n",
        "    9.00000000e+00]\n",
        " [  6.27000000e+02   8.91699982e+01   5.10000000e+01   1.00000000e+00\n",
        "    9.00000000e+00]\n",
        " [  3.80900000e+03   1.02309998e+02   9.00000000e+00   2.00000000e+01\n",
        "    1.90000000e+01]\n",
        " [  8.35700000e+03   9.00599976e+01   5.10000000e+01   1.90000000e+01\n",
        "    1.90000000e+01]]\n",
        "Number of rows: 4209\n",
        "Number of cols: 378\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Load the encoder"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# model_file = \"encoder_dim_20_mean_absolute_error.h5\"\n",
      "model_file = \"encoder_dim_48_mean_absolute_error.h5\"\n",
      "encoder = load_model(model_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python3.5/dist-packages/Keras-2.0.4-py3.5.egg/keras/models.py:257: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
        "  warnings.warn('No training configuration found in save file: '\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encoded_features = encoder.predict(features_ID_y[:,2:])\n",
      "print(encoded_features.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4209, 48)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Loss function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def R2(y_true, y_pred):\n",
      "    S_res = K.sum(K.square(y_true - y_pred))\n",
      "    y_bar = K.mean(y_true)\n",
      "    S_tot = K.sum(K.square(y_true - y_bar))\n",
      "    return -(1.0 - (S_res/S_tot))\n",
      "\n",
      "def R2_np(y_true, y_pred):\n",
      "    S_res = np.sum((y_true - y_pred)*(y_true - y_pred))\n",
      "    y_bar = np.mean(y_true)\n",
      "    S_tot = np.sum((y_true - y_bar)*(y_true - y_bar))\n",
      "    return (1.0 - (S_res/S_tot))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a1 = K.random_normal_variable(shape=(3, 1), mean=0.0, scale=1.0) \n",
      "a2 = K.random_normal_variable(shape=(3, 1), mean=0.0, scale=1.0)\n",
      "\n",
      "r = R2(a1, a2)\n",
      "K.eval(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "3.5195498"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1 = np.array([1,2,3,4])\n",
      "b2 = np.array([1,2.1,3,3.9])\n",
      "\n",
      "R2_np(b1, b2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.996"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Simple Network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Network:\n",
      "    \n",
      "    def __init__(self, \n",
      "                 input_shape=16, \n",
      "                 output_shape=1, \n",
      "                 layers = []):\n",
      "\n",
      "        dropout_rate = 0.5\n",
      "        alpha = 0.3\n",
      "        \n",
      "        model_input = Input(shape=(input_shape,))\n",
      "        x = model_input\n",
      "        for l in range(len(layers)):\n",
      "            x = Dense(layers[l], activation=\"linear\")(x)\n",
      "            x = LeakyReLU(alpha=alpha)(x)\n",
      "            x = Dropout(dropout_rate)(x)\n",
      "        \n",
      "        x = Dense(output_shape, activation='linear')(x)\n",
      "        \n",
      "        self.model = Model(model_input, x)\n",
      "        self.model.compile(optimizer=\"adadelta\", loss=R2)\n",
      "        \n",
      "    def fit(self, x, y, xv, yv, batch_size=128, epochs=100, verbose=0):\n",
      "        self.model.fit(x=x, \n",
      "                       y=y, \n",
      "                       batch_size=batch_size, \n",
      "                       epochs=epochs, \n",
      "                       verbose=verbose,\n",
      "                       validation_data=(xv, yv))\n",
      "        \n",
      "    def predict(self, x, batch_size=128):\n",
      "        return self.model.predict(x, batch_size=batch_size)\n",
      "    \n",
      "    def evaluate(self, x, y, verbose=0):\n",
      "        return self.model.evaluate(x=x, y=y, verbose=verbose)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "network_model = Network(input_shape=364, layers=[32, 32, 32, 32])\n",
      "network_model.model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input_1 (InputLayer)         (None, 364)               0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 32)                11680     \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_1 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 32)                1056      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_2 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_3 (Dense)              (None, 32)                1056      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_3 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_4 (Dense)              (None, 32)                1056      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_4 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_5 (Dense)              (None, 1)                 33        \n",
        "=================================================================\n",
        "Total params: 14,881\n",
        "Trainable params: 14,881\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Many model cross validation approach"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def corss_validation(data,\n",
      "                     n_sections,\n",
      "                     ts=0.2,\n",
      "                     epochs=10,\n",
      "                     layers=[32, 32, 32, 32]):\n",
      "    n_sections = 10\n",
      "    n_rows = len(data)\n",
      "    step = int(n_rows/n_sections)\n",
      "    print(\"step (validation size): \" + str(step))\n",
      "    ptr = 0\n",
      "    network_models = []\n",
      "    \n",
      "    \n",
      "    train_valid = data[0:int((1 - ts)*n_rows),:]\n",
      "    test = data[int((1 - ts)*n_rows):,:]\n",
      "    \n",
      "    y_test = test[:, 0]\n",
      "    x_test = test[:, 1:]\n",
      "    y_test = np.reshape(y_test, (-1, 1))\n",
      "    y_test_pred_avarage = np.zeros((len(y_test), 1))\n",
      "    \n",
      "    print(\"train_valid shape: \" + str(train_valid.shape))\n",
      "    print(\"test shape: \" + str(test.shape))\n",
      "    \n",
      "    for i in range(n_sections):\n",
      "        print(\"\\nIn section i = \" + str(i))\n",
      "        \n",
      "        local_valid = train_valid[ptr:(ptr + step), :]\n",
      "\n",
      "        rows_to_delete = np.arange(ptr, ptr + step)\n",
      "        local_train = np.delete(train_valid, rows_to_delete, 0)\n",
      "        ptr = ptr + step\n",
      "        \n",
      "        y_valid = local_valid[:, 0]\n",
      "        x_valid = local_valid[:, 1:]\n",
      "        \n",
      "        y_train = local_train[:, 0]\n",
      "        x_train = local_train[:, 1:]\n",
      "        \n",
      "        lrv, lcv = x_valid.shape\n",
      "        lrt, lct = x_train.shape\n",
      "        \n",
      "        if (lcv != lct):\n",
      "            print(\"x_valid and x_train dimension mismatch!\")\n",
      "            break\n",
      "        \n",
      "        local_network_model = Network(input_shape=lcv, layers=layers)\n",
      "        local_network_model.fit(x_train, \n",
      "                                y_train, \n",
      "                                x_valid, \n",
      "                                y_valid, \n",
      "                                epochs=epochs, \n",
      "                                verbose=0)\n",
      "        \n",
      "        y_valid_pred = local_network_model.predict(x_valid)\n",
      "        y_train_pred = local_network_model.predict(x_train)\n",
      "        \n",
      "        y_valid = np.reshape(y_valid, (-1, 1))\n",
      "        local_valid_R2 = R2_np(y_valid, y_valid_pred)\n",
      "        \n",
      "        y_train = np.reshape(y_train, (-1, 1))\n",
      "        local_train_R2 = R2_np(y_train, y_train_pred)\n",
      "        \n",
      "        print(\"local_train_R2: \" + str(local_train_R2))\n",
      "        print(\"local_valid_R2: \" + str(local_valid_R2))\n",
      "        print(\"local_valid shape: \" + str(local_valid.shape))\n",
      "        print(\"local_train shape: \" + str(local_train.shape))\n",
      "        \n",
      "        network_models.append(local_network_model)\n",
      "    \n",
      "    \n",
      "        y_test_pred = local_network_model.predict(x_test)\n",
      "        local_test_R2 = R2_np(y_test, y_test_pred)\n",
      "        \n",
      "        y_test_pred_avarage = y_test_pred_avarage + y_test_pred\n",
      "        print(\"local_test_R2: \" + str(local_test_R2))\n",
      "        \n",
      "    y_test_pred_avarage = y_test_pred_avarage/n_sections\n",
      "    average_R2 = R2_np(y_test, y_test_pred_avarage)\n",
      "    print(\"\\naverage R2: \" + str(average_R2))\n",
      "    \n",
      "    return network_models"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.reshape(features_ID_y[:,1],(-1, 1))\n",
      "features_y = np.hstack((y, encoded_features))\n",
      "\n",
      "many_models = corss_validation(data=features_y, \n",
      "                               n_sections=10,\n",
      "                               ts=0.1,\n",
      "                               epochs=10,\n",
      "                               layers=[32, 32, 32, 32])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "step (validation size): 420\n",
        "train_valid shape: (3788, 49)\n",
        "test shape: (421, 49)\n",
        "\n",
        "In section i = 0\n",
        "local_train_R2: -5.1940462732"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -5.05456795678\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -5.53528427764\n",
        "\n",
        "In section i = 1\n",
        "local_train_R2: -2.37349014709"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -2.2683922803\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -2.58774369914\n",
        "\n",
        "In section i = 2\n",
        "local_train_R2: -1.92950919863"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -1.4440278655\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -2.04037334307\n",
        "\n",
        "In section i = 3\n",
        "local_train_R2: -2.73466905046"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -3.21583957054\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -3.1849145922\n",
        "\n",
        "In section i = 4\n",
        "local_train_R2: -3.21903975025"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -3.62361919812\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -3.546476721\n",
        "\n",
        "In section i = 5\n",
        "local_train_R2: -2.26434746063"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -2.40455661696\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -2.62404424872\n",
        "\n",
        "In section i = 6\n",
        "local_train_R2: -2.78845950023"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -2.86156704171\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -3.07233963708\n",
        "\n",
        "In section i = 7\n",
        "local_train_R2: -2.86290542243"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -3.43680235928\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -3.17296161389\n",
        "\n",
        "In section i = 8\n",
        "local_train_R2: -2.49165319113"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -2.96037248328\n",
        "local_valid shape: (420, 49)\n",
        "local_train shape: (3368, 49)\n",
        "local_test_R2: -2.8395339317\n",
        "\n",
        "In section i = 9\n",
        "local_train_R2: -1.60297351442"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local_valid_R2: -2.69783172551\n",
        "local_valid shape: (8, 49)\n",
        "local_train shape: (3780, 49)\n",
        "local_test_R2: -1.78455667177\n",
        "\n",
        "average R2: -2.89842577572\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "XGBoost models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Dispatch on real test data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Read the test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_features_ID_y = np.genfromtxt(\"test_features_ID_y.csv\", delimiter=',')\n",
      "n_rows_ts, n_cols_ts = test_features_ID_y.shape\n",
      "print(\"Test featuers shape: \" + str(test_features_ID_y.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Encoder the test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encoded_test_features = encoder.predict(test_features_ID_y[:,2:])\n",
      "print(encoded_test_features.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_with_many_models(many_models, data):\n",
      "    \n",
      "    n_rows_data, n_cols_data = data.shape\n",
      "    res = np.zeros((n_rows_data, 1))\n",
      "    \n",
      "    n_models = len(many_models)\n",
      "    for i in range(n_models):\n",
      "        res = res + many_models[i].predict(data)\n",
      "    res = res/n_models\n",
      "    \n",
      "    return res\n",
      "\n",
      "def save_res(file_name, res, id_col):\n",
      "\n",
      "    f = open(file_name, \"w\")\n",
      "    f.write(\"ID,y\\n\")\n",
      "    for i in range(len(res)):\n",
      "        s = str(int(id_col[i])) + \",\" + str(res[i][0]) + \"\\n\"\n",
      "        f.write(s)\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = predict_with_many_models(many_models, encoded_test_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_res(\"temp.csv\", res, test_features_ID_y[:,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scratchpad"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_features_ID_y[:,0:1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}