{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tadek/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, Sequential\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.85900000e+03   9.13199997e+01   4.50000000e+01   1.00000000e+00\n",
      "    9.00000000e+00]\n",
      " [  3.07800000e+03   1.11419998e+02   4.90000000e+01   1.40000000e+01\n",
      "    5.00000000e+00]\n",
      " [  8.73000000e+02   8.96600037e+01   4.00000000e+01   1.30000000e+01\n",
      "    1.90000000e+01]\n",
      " [  6.11900000e+03   1.11050003e+02   5.00000000e+01   2.30000000e+01\n",
      "    2.90000000e+01]\n",
      " [  3.10300000e+03   1.11150002e+02   2.30000000e+01   1.00000000e+01\n",
      "    1.90000000e+01]\n",
      " [  7.08400000e+03   7.63199997e+01   2.80000000e+01   2.50000000e+01\n",
      "    3.00000000e+00]\n",
      " [  5.31400000e+03   1.08860001e+02   6.00000000e+00   2.00000000e+01\n",
      "    1.90000000e+01]\n",
      " [  7.46800000e+03   8.90500031e+01   4.60000000e+01   1.00000000e+00\n",
      "    5.00000000e+00]\n",
      " [  8.39000000e+03   9.99300003e+01   5.10000000e+01   1.60000000e+01\n",
      "    3.70000000e+01]\n",
      " [  6.36500000e+03   8.08199997e+01   2.40000000e+01   1.30000000e+01\n",
      "    3.80000000e+01]]\n",
      "Number of rows: 4209\n",
      "Number of cols: 378\n"
     ]
    }
   ],
   "source": [
    "features_ID_y = np.genfromtxt(\"features_ID_y.csv\", delimiter=',')\n",
    "np.random.shuffle(features_ID_y)\n",
    "n_rows, n_cols = features_ID_y.shape\n",
    "print(features_ID_y[0:10,0:5])\n",
    "print(\"Number of rows: \" + str(n_rows))\n",
    "print(\"Number of cols: \" + str(n_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/Keras-2.0.4-py3.5.egg/keras/models.py:257: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_file = \"encoder_dim_64_mean_absolute_error.h5\"\n",
    "# model_file = \"encoder_dim_48_mean_absolute_error.h5\"\n",
    "encoder = load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_input (InputLaye (None, 376)               0         \n",
      "_________________________________________________________________\n",
      "encoder_first_layer (Dense)  (None, 128)               48256     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "encoder_first_layer_dropout  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "encoder (Dropout)            (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 56,512\n",
      "Trainable params: 56,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 376)\n",
      "(4209, 64)\n"
     ]
    }
   ],
   "source": [
    "print(features_ID_y[:,2:].shape)\n",
    "encoded_features = encoder.predict(features_ID_y[:,2:])\n",
    "print(encoded_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred):\n",
    "    S_res = K.sum(K.square(y_true - y_pred))\n",
    "    y_bar = K.mean(y_true)\n",
    "    S_tot = K.sum(K.square(y_true - y_bar))\n",
    "    return -(1.0 - (S_res/S_tot))\n",
    "\n",
    "def R2_np(y_true, y_pred):\n",
    "    S_res = np.sum((y_true - y_pred)*(y_true - y_pred))\n",
    "    y_bar = np.mean(y_true)\n",
    "    S_tot = np.sum((y_true - y_bar)*(y_true - y_bar))\n",
    "    return (1.0 - (S_res/S_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1304522"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = K.random_normal_variable(shape=(3, 1), mean=0.0, scale=1.0) \n",
    "a2 = K.random_normal_variable(shape=(3, 1), mean=0.0, scale=1.0)\n",
    "\n",
    "r = R2(a1, a2)\n",
    "K.eval(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = np.array([1,2,3,4])\n",
    "b2 = np.array([1,2.1,3,3.9])\n",
    "\n",
    "R2_np(b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_shape=16, \n",
    "                 output_shape=1, \n",
    "                 layers = []):\n",
    "\n",
    "        dropout_rate = 0.5\n",
    "        alpha = 0.3\n",
    "        \n",
    "        model_input = Input(shape=(input_shape,))\n",
    "        x = model_input\n",
    "        for l in range(len(layers)):\n",
    "            x = Dense(layers[l], activation=\"linear\")(x)\n",
    "            x = LeakyReLU(alpha=alpha)(x)\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "        x = Dense(output_shape, activation='linear')(x)\n",
    "        \n",
    "        self.model = Model(model_input, x)\n",
    "        self.model.compile(optimizer=\"adadelta\", loss=R2)\n",
    "        \n",
    "    def fit(self, x, y, xv, yv, batch_size=128, epochs=100, verbose=0):\n",
    "        self.model.fit(x=x, \n",
    "                       y=y, \n",
    "                       batch_size=batch_size, \n",
    "                       epochs=epochs, \n",
    "                       verbose=verbose,\n",
    "                       validation_data=(xv, yv))\n",
    "        \n",
    "    def predict(self, x, batch_size=128):\n",
    "        return self.model.predict(x, batch_size=batch_size)\n",
    "    \n",
    "    def evaluate(self, x, y, verbose=0):\n",
    "        return self.model.evaluate(x=x, y=y, verbose=verbose)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 364)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                11680     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,881\n",
      "Trainable params: 14,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network_model = Network(input_shape=364, layers=[32, 32, 32, 32])\n",
    "network_model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Many model cross validation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corss_validation(data,\n",
    "                     n_sections,\n",
    "                     ts=0.2,\n",
    "                     epochs=10,\n",
    "                     layers=[32, 32, 32, 32]):\n",
    "    n_sections = 10\n",
    "    n_rows = len(data)\n",
    "    step = int(n_rows/n_sections)\n",
    "    print(\"step (validation size): \" + str(step))\n",
    "    ptr = 0\n",
    "    network_models = []\n",
    "    \n",
    "    \n",
    "    train_valid = data[0:int((1 - ts)*n_rows),:]\n",
    "    test = data[int((1 - ts)*n_rows):,:]\n",
    "    \n",
    "    y_test = test[:, 0]\n",
    "    x_test = test[:, 1:]\n",
    "    y_test = np.reshape(y_test, (-1, 1))\n",
    "    y_test_pred_avarage = np.zeros((len(y_test), 1))\n",
    "    \n",
    "    print(\"train_valid shape: \" + str(train_valid.shape))\n",
    "    print(\"test shape: \" + str(test.shape))\n",
    "    \n",
    "    for i in range(n_sections):\n",
    "        print(\"\\nIn section i = \" + str(i))\n",
    "        \n",
    "        local_valid = train_valid[ptr:(ptr + step), :]\n",
    "\n",
    "        rows_to_delete = np.arange(ptr, ptr + step)\n",
    "        local_train = np.delete(train_valid, rows_to_delete, 0)\n",
    "        ptr = ptr + step\n",
    "        \n",
    "        y_valid = local_valid[:, 0]\n",
    "        x_valid = local_valid[:, 1:]\n",
    "        \n",
    "        y_train = local_train[:, 0]\n",
    "        x_train = local_train[:, 1:]\n",
    "        \n",
    "        lrv, lcv = x_valid.shape\n",
    "        lrt, lct = x_train.shape\n",
    "        \n",
    "        if (lcv != lct):\n",
    "            print(\"x_valid and x_train dimension mismatch!\")\n",
    "            break\n",
    "        \n",
    "        local_network_model = Network(input_shape=lcv, layers=layers)\n",
    "        local_network_model.fit(x_train, \n",
    "                                y_train, \n",
    "                                x_valid, \n",
    "                                y_valid, \n",
    "                                epochs=epochs, \n",
    "                                verbose=0)\n",
    "        \n",
    "        y_valid_pred = local_network_model.predict(x_valid)\n",
    "        y_train_pred = local_network_model.predict(x_train)\n",
    "        \n",
    "        y_valid = np.reshape(y_valid, (-1, 1))\n",
    "        local_valid_R2 = R2_np(y_valid, y_valid_pred)\n",
    "        \n",
    "        y_train = np.reshape(y_train, (-1, 1))\n",
    "        local_train_R2 = R2_np(y_train, y_train_pred)\n",
    "        \n",
    "        print(\"local_train_R2: \" + str(local_train_R2))\n",
    "        print(\"local_valid_R2: \" + str(local_valid_R2))\n",
    "        print(\"local_valid shape: \" + str(local_valid.shape))\n",
    "        print(\"local_train shape: \" + str(local_train.shape))\n",
    "        \n",
    "        network_models.append(local_network_model)\n",
    "    \n",
    "    \n",
    "        y_test_pred = local_network_model.predict(x_test)\n",
    "        local_test_R2 = R2_np(y_test, y_test_pred)\n",
    "        \n",
    "        y_test_pred_avarage = y_test_pred_avarage + y_test_pred\n",
    "        print(\"local_test_R2: \" + str(local_test_R2))\n",
    "        \n",
    "    y_test_pred_avarage = y_test_pred_avarage/n_sections\n",
    "    average_R2 = R2_np(y_test, y_test_pred_avarage)\n",
    "    print(\"\\naverage R2: \" + str(average_R2))\n",
    "    \n",
    "    return network_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 65)\n",
      "step (validation size): 420\n",
      "train_valid shape: (3788, 65)\n",
      "test shape: (421, 65)\n",
      "\n",
      "In section i = 0\n",
      "local_train_R2: 0.57435781179\n",
      "local_valid_R2: 0.695356057214\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.566097912475\n",
      "\n",
      "In section i = 1\n",
      "local_train_R2: 0.595267972407\n",
      "local_valid_R2: 0.450356332061\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.567660546192\n",
      "\n",
      "In section i = 2\n",
      "local_train_R2: 0.574437083792\n",
      "local_valid_R2: 0.550496028076\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.545233451579\n",
      "\n",
      "In section i = 3\n",
      "local_train_R2: 0.585851985914\n",
      "local_valid_R2: 0.495668631224\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.558006394812\n",
      "\n",
      "In section i = 4\n",
      "local_train_R2: 0.577496343767\n",
      "local_valid_R2: 0.599821858762\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.543777240878\n",
      "\n",
      "In section i = 5\n",
      "local_train_R2: 0.593926774037\n",
      "local_valid_R2: 0.557370806982\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.564960548427\n",
      "\n",
      "In section i = 6\n",
      "local_train_R2: 0.589785025832\n",
      "local_valid_R2: 0.504674762033\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.56683320161\n",
      "\n",
      "In section i = 7\n",
      "local_train_R2: 0.56748200759\n",
      "local_valid_R2: 0.566860742459\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.545173764331\n",
      "\n",
      "In section i = 8\n",
      "local_train_R2: 0.615273706712\n",
      "local_valid_R2: 0.353555774218\n",
      "local_valid shape: (420, 65)\n",
      "local_train shape: (3368, 65)\n",
      "local_test_R2: 0.546610774877\n",
      "\n",
      "In section i = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tadek/.local/lib/python3.5/site-packages/ipykernel_launcher.py:31: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_train_R2: 0.586824907206\n",
      "local_valid_R2: 0.656831560681\n",
      "local_valid shape: (8, 65)\n",
      "local_train shape: (3780, 65)\n",
      "local_test_R2: 0.562288580852\n",
      "\n",
      "average R2: 0.560490945917\n"
     ]
    }
   ],
   "source": [
    "y = np.reshape(features_ID_y[:,1],(-1, 1))\n",
    "features_y = np.hstack((y, encoded_features))\n",
    "\n",
    "print(features_y.shape)\n",
    "\n",
    "many_models = corss_validation(data=features_y, \n",
    "                               n_sections=10,\n",
    "                               ts=0.1,\n",
    "                               epochs=2000,\n",
    "                               layers=[64, 64, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispatch on real test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test featuers shape: (4209, 378)\n"
     ]
    }
   ],
   "source": [
    "test_features_ID_y = np.genfromtxt(\"test_features_ID_y.csv\", delimiter=',')\n",
    "n_rows_ts, n_cols_ts = test_features_ID_y.shape\n",
    "print(\"Test featuers shape: \" + str(test_features_ID_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Encoder the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 64)\n"
     ]
    }
   ],
   "source": [
    "encoded_test_features = encoder.predict(test_features_ID_y[:,2:])\n",
    "print(encoded_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_with_many_models(many_models, data):\n",
    "    \n",
    "    n_rows_data, n_cols_data = data.shape\n",
    "    res = np.zeros((n_rows_data, 1))\n",
    "    \n",
    "    n_models = len(many_models)\n",
    "    for i in range(n_models):\n",
    "        res = res + many_models[i].predict(data)\n",
    "    res = res/n_models\n",
    "    \n",
    "    return res\n",
    "\n",
    "def save_res(file_name, res, id_col):\n",
    "\n",
    "    f = open(file_name, \"w\")\n",
    "    f.write(\"ID,y\\n\")\n",
    "    for i in range(len(res)):\n",
    "        s = str(int(id_col[i])) + \",\" + str(res[i][0]) + \"\\n\"\n",
    "        f.write(s)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = predict_with_many_models(many_models, encoded_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_res(\"temp.csv\", res, test_features_ID_y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  78.41011658],\n",
       "       [  93.10310135],\n",
       "       [  78.26832428],\n",
       "       [  78.28930206],\n",
       "       [ 109.22426605],\n",
       "       [  90.99972382],\n",
       "       [ 107.75654449],\n",
       "       [  94.8952652 ],\n",
       "       [ 115.06167526],\n",
       "       [  93.6342926 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00],\n",
       "       [  2.00000000e+00],\n",
       "       [  3.00000000e+00],\n",
       "       ..., \n",
       "       [  8.41300000e+03],\n",
       "       [  8.41400000e+03],\n",
       "       [  8.41600000e+03]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_ID_y[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
