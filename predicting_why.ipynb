{
 "metadata": {
  "name": "",
  "signature": "sha256:642d1c1f6cb50f29bf4cbe14fe1f1b9092c2146f3fece57e5f5f94cef6c6dbc5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "from keras.layers import Input, Dense, Dropout\n",
      "from keras.layers.advanced_activations import LeakyReLU\n",
      "from keras.models import Model, Sequential\n",
      "import keras.backend as K\n",
      "\n",
      "from keras.models import load_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Load the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_ID_y = np.genfromtxt(\"features_ID_y.csv\", delimiter=',')\n",
      "np.random.shuffle(features_ID_y)\n",
      "n_rows, n_cols = features_ID_y.shape\n",
      "print(features_ID_y[0:10,0:5])\n",
      "print(\"Number of rows: \" + str(n_rows))\n",
      "print(\"Number of cols: \" + str(n_cols))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  4.94100000e+03   8.79700012e+01   5.10000000e+01   0.00000000e+00\n",
        "    1.10000000e+01]\n",
        " [  5.51000000e+03   1.14910004e+02   4.90000000e+01   4.00000000e+00\n",
        "    5.00000000e+00]\n",
        " [  1.91400000e+03   1.08339996e+02   3.50000000e+01   0.00000000e+00\n",
        "    4.00000000e+01]\n",
        " [  7.76400000e+03   1.00029999e+02   3.00000000e+01   7.00000000e+00\n",
        "    1.90000000e+01]\n",
        " [  6.94000000e+02   1.05349998e+02   5.00000000e+01   1.00000000e+00\n",
        "    1.90000000e+01]\n",
        " [  3.98000000e+02   9.89599991e+01   3.00000000e+01   1.00000000e+00\n",
        "    4.80000000e+01]\n",
        " [  3.90900000e+03   1.14800003e+02   1.00000000e+01   2.20000000e+01\n",
        "    1.90000000e+01]\n",
        " [  7.08400000e+03   7.63199997e+01   2.80000000e+01   2.50000000e+01\n",
        "    3.00000000e+00]\n",
        " [  1.45000000e+03   1.08900002e+02   5.00000000e+01   1.00000000e+00\n",
        "    1.90000000e+01]\n",
        " [  8.09900000e+03   1.15139999e+02   5.00000000e+01   1.00000000e+01\n",
        "    1.90000000e+01]]\n",
        "Number of rows: 4209\n",
        "Number of cols: 378\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Load the encoder"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_file = \"encoder_dim_32_mean_absolute_error.h5\"\n",
      "encoder = load_model(model_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python3.5/dist-packages/Keras-2.0.4-py3.5.egg/keras/models.py:257: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
        "  warnings.warn('No training configuration found in save file: '\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encoded_features = encoder.predict(features_ID_y[:,2:])\n",
      "print(encoded_features.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4209, 32)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Loss function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def R2(y_true, y_pred):\n",
      "    S_res = K.sum(K.square(y_true - y_pred))\n",
      "    y_bar = K.mean(y_true)\n",
      "    S_tot = K.sum(K.square(y_true - y_bar))\n",
      "    return -(1.0 - (S_res/S_tot))\n",
      "\n",
      "def R2_np(y_true, y_pred):\n",
      "    S_res = np.sum((y_true - y_pred)*(y_true - y_pred))\n",
      "    y_bar = np.mean(y_true)\n",
      "    S_tot = np.sum((y_true - y_bar)*(y_true - y_bar))\n",
      "    return (1.0 - (S_res/S_tot))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a1 = K.random_normal_variable(shape=(3, 1), mean=0.0, scale=1.0) \n",
      "a2 = K.random_normal_variable(shape=(3, 1), mean=0.0, scale=1.0)\n",
      "\n",
      "r = R2(a1, a2)\n",
      "K.eval(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "2.3011019"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b1 = np.array([1,2,3,4])\n",
      "b2 = np.array([1,2.1,3,3.9])\n",
      "\n",
      "R2_np(b1, b2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.996"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Simple Network"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Network:\n",
      "    \n",
      "    def __init__(self, \n",
      "                 input_shape=16, \n",
      "                 output_shape=1, \n",
      "                 layers = []):\n",
      "\n",
      "        dropout_rate = 0.1\n",
      "        alpha = 0.3\n",
      "        \n",
      "        model_input = Input(shape=(input_shape,))\n",
      "        x = model_input\n",
      "        for l in range(len(layers)):\n",
      "            x = Dense(layers[l], activation=\"linear\")(x)\n",
      "            x = LeakyReLU(alpha=alpha)(x)\n",
      "            x = Dropout(dropout_rate)(x)\n",
      "        \n",
      "        x = Dense(output_shape, activation='linear')(x)\n",
      "        \n",
      "        self.model = Model(model_input, x)\n",
      "        self.model.compile(optimizer=\"adadelta\", loss=R2)\n",
      "        \n",
      "    def fit(self, x, y, xv, yv, batch_size=128, epochs=100, verbose=0):\n",
      "        self.model.fit(x=x, \n",
      "                       y=y, \n",
      "                       batch_size=batch_size, \n",
      "                       epochs=epochs, \n",
      "                       verbose=verbose,\n",
      "                       validation_data=(xv, yv))\n",
      "        \n",
      "    def predict(self, x, batch_size=128):\n",
      "        return self.model.predict(x, batch_size=batch_size)\n",
      "    \n",
      "    def evaluate(self, x, y, verbose=0):\n",
      "        return self.model.evaluate(x=x, y=y, verbose=verbose)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "network_model = Network(input_shape=364, layers=[32, 32, 32, 32])\n",
      "network_model.model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input_1 (InputLayer)         (None, 364)               0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 32)                11680     \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_1 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_1 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 32)                1056      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_2 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_3 (Dense)              (None, 32)                1056      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_3 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_4 (Dense)              (None, 32)                1056      \n",
        "_________________________________________________________________\n",
        "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dropout_4 (Dropout)          (None, 32)                0         \n",
        "_________________________________________________________________\n",
        "dense_5 (Dense)              (None, 1)                 33        \n",
        "=================================================================\n",
        "Total params: 14,881\n",
        "Trainable params: 14,881\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Many model cross validation approach"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def corss_validation(data,\n",
      "                     n_sections,\n",
      "                     ts=0.2,\n",
      "                     epochs=10,\n",
      "                     layers=[32, 32, 32, 32]):\n",
      "    n_sections = 10\n",
      "    n_rows = len(data)\n",
      "    step = int(n_rows/n_sections)\n",
      "    print(\"step (validation size): \" + str(step))\n",
      "    ptr = 0\n",
      "    network_models = []\n",
      "    \n",
      "    \n",
      "    train_valid = data[0:int((1 - ts)*n_rows),:]\n",
      "    test = data[int((1 - ts)*n_rows):,:]\n",
      "    \n",
      "    y_test = test[:, 0]\n",
      "    x_test = test[:, 1:]\n",
      "    y_test = np.reshape(y_test, (-1, 1))\n",
      "    y_test_pred_avarage = np.zeros((len(y_test), 1))\n",
      "    \n",
      "    print(\"train_valid shape: \" + str(train_valid.shape))\n",
      "    print(\"test shape: \" + str(test.shape))\n",
      "    \n",
      "    for i in range(n_sections):\n",
      "        print(\"\\nIn section i = \" + str(i))\n",
      "        \n",
      "        local_valid = train_valid[ptr:(ptr + step), :]\n",
      "\n",
      "        rows_to_delete = np.arange(ptr, ptr + step)\n",
      "        local_train = np.delete(train_valid, rows_to_delete, 0)\n",
      "        ptr = ptr + step\n",
      "        \n",
      "        y_valid = local_valid[:, 0]\n",
      "        x_valid = local_valid[:, 1:]\n",
      "        \n",
      "        y_train = local_train[:, 0]\n",
      "        x_train = local_train[:, 1:]\n",
      "        \n",
      "        lrv, lcv = x_valid.shape\n",
      "        lrt, lct = x_train.shape\n",
      "        \n",
      "        if (lcv != lct):\n",
      "            print(\"x_valid and x_train dimension mismatch!\")\n",
      "            break\n",
      "        \n",
      "        local_network_model = Network(input_shape=lcv, layers=layers)\n",
      "        local_network_model.fit(x_train, \n",
      "                                y_train, \n",
      "                                x_valid, \n",
      "                                y_valid, \n",
      "                                epochs=epochs, \n",
      "                                verbose=0)\n",
      "        \n",
      "        y_valid_pred = local_network_model.predict(x_valid)\n",
      "        y_train_pred = local_network_model.predict(x_train)\n",
      "        \n",
      "        y_valid = np.reshape(y_valid, (-1, 1))\n",
      "        local_valid_R2 = R2_np(y_valid, y_valid_pred)\n",
      "        \n",
      "        y_train = np.reshape(y_train, (-1, 1))\n",
      "        local_train_R2 = R2_np(y_train, y_train_pred)\n",
      "        \n",
      "        print(\"local_train_R2: \" + str(local_train_R2))\n",
      "        print(\"local_valid_R2: \" + str(local_valid_R2))\n",
      "        # print(\"local_valid shape: \" + str(local_valid.shape))\n",
      "        # print(\"local_train shape: \" + str(local_train.shape))\n",
      "        \n",
      "        network_models.append(local_network_model)\n",
      "    \n",
      "    \n",
      "        y_test_pred = local_network_model.predict(x_test)\n",
      "        local_test_R2 = R2_np(y_test, y_test_pred)\n",
      "        \n",
      "        y_test_pred_avarage = y_test_pred_avarage + y_test_pred\n",
      "        print(\"local_test_R2: \" + str(local_test_R2))\n",
      "        \n",
      "    y_test_pred_avarage = y_test_pred_avarage/n_sections\n",
      "    average_R2 = R2_np(y_test, y_test_pred_avarage)\n",
      "    print(\"\\naverage R2: \" + str(average_R2))\n",
      "    \n",
      "    return network_models"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.reshape(features_ID_y[:,1],(-1, 1))\n",
      "features_y = np.hstack((y, encoded_features))\n",
      "\n",
      "many_models = corss_validation(data=features_y, \n",
      "                               n_sections=10,\n",
      "                               ts=0.1,\n",
      "                               epochs=2000,\n",
      "                               layers=[32, 32, 32, 32])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Dispatch on real test data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Read the test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_features_ID_y = np.genfromtxt(\"test_features_ID_y.csv\", delimiter=',')\n",
      "n_rows_ts, n_cols_ts = test_features_ID_y.shape\n",
      "print(\"Test featuers shape: \" + str(test_features_ID_y.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Encoder the test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encoded_test_features = encoder.predict(test_features_ID_y[:,2:])\n",
      "print(encoded_test_features.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_with_many_models(many_models, data):\n",
      "    \n",
      "    n_rows_data, n_cols_data = data.shape\n",
      "    res = np.zeros((n_rows_data, 1))\n",
      "    \n",
      "    n_models = len(many_models)\n",
      "    for i in range(n_models):\n",
      "        res = res + many_models[i].predict(data)\n",
      "    res = res/n_models\n",
      "    \n",
      "    return res\n",
      "\n",
      "def save_res(file_name, res, id_col):\n",
      "\n",
      "    f = open(file_name, \"w\")\n",
      "    f.write(\"ID,y\\n\")\n",
      "    for i in range(len(res)):\n",
      "        s = str(int(id_col[i])) + \",\" + str(res[i][0]) + \"\\n\"\n",
      "        f.write(s)\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = predict_with_many_models(many_models, encoded_test_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_res(\"temp.csv\", res, test_features_ID_y[:,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scratchpad"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_features_ID_y[:,0:1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}